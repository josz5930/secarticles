#"Purple" Teaming

_Inspired by a HITB talk by Ryan Shepherd, Threat Hunter in Countercept_

##### What is a "Purple Team"?
While all teams - Red, Blue or Purple serve to eventually lead to better defenses by the organization, each has a different (although sometimes overlapping role).

The Red Team is a team which performs an attack by emulating the behaviors and techniques of likely attackers in the most realistic way possible. An objective is set before the attack and the red team attempts to achieve the objective. On the opposite end, Blue Teams refer to the internal security team that defends against both real attackers and Red Teams.

Purple Teams are the team which integrates the knowledge gathered by both teams. While the definition of the day to day activities differs quite a bit from organization to organization, the team generally works to gather and use the information of both teams to improve security.

##### Who should be in a "purple" team

People are the most important part of a "purple" team. Great technological tools without the appropriate people will not succeed; trained appropriate people can be the start of effective "purple" team operations, even if they do not have great tools.

For hiring managers, a typical certification profile is someone who has both kinds of certification. For example, a "defensive" type certification such as Crest Registered Intrusion Analyst (CRIA) and an "offensive" type certification such as Offensive Security Certified Expert (OSCE).

##### Example of a purple team in action

In an example provided in the talk at HITB, there was a discovery made of a download of SCR file and powershell execution. This could have been done by analysis of the logged browsing history of users. Another discovery was also made of a reflective loading malware being used. This could have been done by a Red Team, which would have revealed a possible attack vector of how disk-based anti-virus was evaded by the use of that attack (although it was not the case for that client).

Both teams only saw part of the story:

* One saw only the download of SCR attachments and Powershell script loaded into memory via RegSvcs
* The other saw AutoIT script used as secondary stage (probably via the malicious executable)

Therefore, a "purple" team would hae collated that information and came out with a more complete picture in a shorter time.

Typical sophisicated attacks takes about 6 months to execute from initial foothold to actual theft/fraud. A "purple" team would increase the speed of the organization to prevent or mitigate such attacks.

While nothing replaces the experience of an actual attacks, simulated detection labs may help "blue" and "purple" teams get better by analysis of data generated by instrumentation by a "red" team providing simulated attacks.  

Scripts to establish a detection lab is now available on Github to simulate this detection lab. You may read more about this at [this link to the tutorial at Medium](https://medium.com/@clong/introducing-detection-lab-61db34bed6ae). Using such a lab allows blue teams to see attacks in a "clean" environment while mitigating the risk of the "red" team breaking production systems. 

__References:__ 

* https://danielmiessler.com/study/red-blue-purple-teams/
* https://www.tripwire.com/state-of-security/risk-based-security-for-executives/connecting-security-to-the-business/red-team-v-blue-team-they-are-in-fact-one-the-purple-team/
* https://securityaffairs.co/wordpress/49624/hacking/cyber-red-team-blue-team.html
* https://malwaretips.com/threads/detecting-reflective-dll-loading-with-windows-defender-atp.77131/
* https://github.com/clong/DetectionLab
* https://gsec.hitb.org/materials/sg2018/D1%20-%20A%20Year%20of%20Purple%20-%20Ryan%20Shepherd.pdf
* https://medium.com/@clong/introducing-detection-lab-61db34bed6ae
